{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hebermudezg/Machine-Learning/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUVpcsaauf0i",
        "colab_type": "text"
      },
      "source": [
        "# Text Mining with Python\n",
        "---\n",
        "El testo estan en todos lados, libros, noticias, foros, ... et\n",
        "\n",
        "Aproximadamente el 80% de los datos son no estructurados, texto plano. \n",
        "\n",
        "* 40 millones de articulos en Wikipedia\n",
        "\n",
        "* 4500 millones de paginas web.\n",
        "\n",
        "* 500 millones de tweets al dia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Axu_WTydDo",
        "colab_type": "text"
      },
      "source": [
        "**Que podemos hacer con el texto?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rYkg-2DylCJ",
        "colab_type": "text"
      },
      "source": [
        "* Analizar gramaticalmente\n",
        "* Buscar, Identificar y extraer información relevante del texto.\n",
        "* Clasificación de texto\n",
        "* Análisis de sentimientos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UglooLyV34w",
        "colab_type": "text"
      },
      "source": [
        "# NLP\n",
        "---\n",
        "\n",
        "El procesamiento del lenguaje natural (PNL) es una rama del aprendizaje automático que se ocupa del procesamiento, el análisis y, a veces, la generación del habla humana (\"lenguaje natural\").\n",
        "\n",
        "Se usa en:\n",
        "\n",
        "* chatbots \n",
        "* Anásis de sentimientos\n",
        "* Asistetes de voz\n",
        "\n",
        "SpaCy.\n",
        "---\n",
        "spaCy es una biblioteca de procesamiento de lenguaje natural de código abierto para Python. Está diseñado especialmente para uso en producción, y puede ayudarnos a crear aplicaciones que procesen volúmenes masivos de texto de manera eficiente\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pip install spacy\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-hhadZNb53U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"\"\"When hola learning ciencia de datosss, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\n",
        "  12344 #$%&/()=? #$%&/()=?  juan, calos, pedro, por hola  igual, da, general\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-TRzKlBcwWF",
        "colab_type": "text"
      },
      "source": [
        "# Limpieza, Procesamiento de texto\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPQqtPzPTKqt",
        "colab_type": "text"
      },
      "source": [
        "### Tokenización\n",
        "---\n",
        "La tokenización es el proceso de dividir el texto en pedazos, llamados tokens, el texto se puede dividir en palabras individuales y conjuntos de palabras como oraciones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO810Xf7TURu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cargando libreria\n",
        "from spacy.lang.es import Spanish"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCgdqLyIrvPg",
        "colab_type": "code",
        "outputId": "6b71e9b4-47b9-4522-d4e1-3ef7e16bcf43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Cargando tokenizador\n",
        "nlp = Spanish()\n",
        "\n",
        "#  \"nlp\" crear documentos con anotaciones linguisticas\n",
        "my_doc = nlp(text)\n",
        "\n",
        "# creando lista vacia de tokens\n",
        "token_list = []\n",
        "for token in my_doc:\n",
        "    token_list.append(token.text)\n",
        "print(token_list)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['When', 'hola', 'learning', 'ciencia', 'de', 'datosss', ',', 'you', \"shouldn't\", 'get', 'discouraged', '!', '\\n', 'Challenges', 'and', 'setbacks', \"aren't\", 'failures', ',', \"they're\", 'just', 'part', 'of', 'the', 'journey', '.', \"You've\", 'got', 'this', '!', '\\n  ', '12344', '#', '$', '%', '&', '/()=', '?', '#', '$', '%', '&', '/()=', '?', ' ', 'juan', ',', 'calos', ',', 'pedro', ',', 'por', 'hola', ' ', 'igual', ',', 'da', ',', 'general']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf5qBoJbVpft",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizacion por oraciones.\n",
        "---\n",
        "\n",
        "Al realizar la tokenización de oraciones, el tokenizador busca caracteres específicos que se encuentran entre oraciones, como puntos, signos de exclamación y caracteres de nueva línea."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAy6wGLdWdrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "11859203-0e55-4c36-e4d4-88fa1e12ce5a"
      },
      "source": [
        "# cargando tokenizador\n",
        "nlp = Spanish()\n",
        "\n",
        "# Crear el componente de canalización 'sentencizer'\n",
        "sbd = nlp.create_pipe('sentencizer')\n",
        "\n",
        "# Agregar el componente a la tubería\n",
        "nlp.add_pipe(sbd)\n",
        "\n",
        "#  \"nlp\" para crear documentos con anotaciones linguisticas\n",
        "doc = nlp(text)\n",
        "\n",
        "# creando lista de tokens(oraciones)\n",
        "sents_list = []\n",
        "for sent in doc.sents:\n",
        "    sents_list.append(sent.text)\n",
        "print(sents_list)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"When hola learning ciencia de datosss, you shouldn't get discouraged!\", \"\\nChallenges and setbacks aren't failures, they're just part of the journey.\", \"You've got this!\", '\\n  12344 #$%&/()=? #', '$%&/()=?', ' juan, calos, pedro, por hola  igual, da, general']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIVWsRmJYNb6",
        "colab_type": "text"
      },
      "source": [
        "### Eliminación de palabras vacías (Stopwords)\n",
        "---\n",
        "\n",
        "La mayoría de los datos de texto con los que trabajamos contendrán muchas palabras que en realidad no nos son útiles. Estas palabras, llamadas palabras vacías , son útiles en el habla humana, pero no tienen mucho que aportar al análisis de datos. (conjunciones, pronombres, etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_5AUf-PYiz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d080c7f2-65ae-4aa1-fee0-3477cbbe4a04"
      },
      "source": [
        "# Importando palabras vacias en español\n",
        "import spacy\n",
        "spacy_stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
        "\n",
        "#Printing the total number of stop words:\n",
        "print('Número de palabras vacias: %d' % len(spacy_stopwords))\n",
        "\n",
        "#Printing first ten stop words:\n",
        "print('Primeras 10 palabras vacias: %s' % list(spacy_stopwords)[:10])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de palabras vacias: 551\n",
            "Primeras 10 palabras vacias: ['igual', 'da', 'debido', 'debajo', 'ir', 'modo', 'encima', 'general', 'dijo', 'pasado']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsfJMJ6VZOMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "366fd996-08ff-4720-f66d-2b743d8d0677"
      },
      "source": [
        "from spacy.lang.es.stop_words import STOP_WORDS\n",
        "\n",
        "# Lista de palabras filtradas\n",
        "filtered_sent=[]\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "# filtrando palabras vacias. \n",
        "for word in doc:\n",
        "    if word.is_stop==False:\n",
        "        filtered_sent.append(word)\n",
        "print(\"Filtrados:\",filtered_sent)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filtrados: [When, hola, learning, ciencia, datosss, ,, you, shouldn't, get, discouraged, !, \n",
            ", Challenges, and, setbacks, aren't, failures, ,, they're, just, part, of, the, journey, ., You've, got, this, !, \n",
            "  , 12344, #, $, %, &, /()=, ?, #, $, %, &, /()=, ?,  , juan, ,, calos, ,, pedro, ,, hola,  , ,, ,]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQf9AwYzcdYW",
        "colab_type": "text"
      },
      "source": [
        "# Normalización de léxico\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSHs_voLdTrR",
        "colab_type": "text"
      },
      "source": [
        "### Lematización\n",
        "---\n",
        "\n",
        "La lematización es una forma de lidiar con el hecho de que, aunque palabras como conecta , conectó , conectarian , etc. no son exactamente lo mismo, todas tienen el mismo significado esencial: conectar ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxZ4yYcncpWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bc5f516f-e348-424e-e952-2598f174fcfb"
      },
      "source": [
        "# Implementing lemmatization\n",
        "lem = nlp(\"jugar jugaron jugarian jugamos correr correrían\")\n",
        "# finding lemma for each word\n",
        "for word in lem:\n",
        "    print(word.text,word.lemma_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jugar jugar\n",
            "jugaron jugar\n",
            "jugarian jugarian\n",
            "jugamos jugar\n",
            "correr correr\n",
            "correrían correr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Ee6lSleZPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99bb288e-b07b-48c4-cb02-8965af4a24a3"
      },
      "source": [
        "nlp"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.es.Spanish at 0x7f9935330240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix1DpDUOendV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}